{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import required libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 2: Load the Titanic dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Step 3: Drop unnecessary or mostly-empty columns\n",
        "df = df.drop(columns=['deck', 'embark_town', 'alive'])\n",
        "\n",
        "# Step 4: Handle missing values\n",
        "df['age'] = df['age'].fillna(df['age'].mean())   # âœ… Fix: no inplace=True\n",
        "df = df.dropna(subset=['embarked'])              # Drop rows where 'embarked' is missing\n",
        "df = df.dropna()                                 # Drop any remaining missing data\n",
        "\n",
        "# Step 5: Convert categorical columns to numeric using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object' or str(df[col].dtype) == 'category':\n",
        "        df[col] = label_encoder.fit_transform(df[col].astype(str))  # âœ… Fix: convert to str\n",
        "\n",
        "# Step 6: Normalize numerical columns using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
        "\n",
        "# Step 7: Split the data into features (X) and target (y)\n",
        "X = df.drop('survived', axis=1)  # Features\n",
        "y = df['survived']               # Target\n",
        "\n",
        "# Step 8: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 9: Train a Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 10: Predict and evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nâœ… Model Accuracy: {:.2f}%\".format(accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqRX3_TsX6g4",
        "outputId": "7c346f20-13b6-4f4f-beac-b883062f381e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Model Accuracy: 80.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 2: Load dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Step 3: Drop unnecessary or mostly empty columns\n",
        "df = df.drop(columns=['deck', 'embark_town', 'alive'])\n",
        "\n",
        "# Step 4: Handle missing values\n",
        "df['age'] = df['age'].fillna(df['age'].mean())\n",
        "df = df.dropna(subset=['embarked'])\n",
        "df = df.dropna()\n",
        "\n",
        "# Step 5: Encode categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object' or str(df[col].dtype) == 'category':\n",
        "        df[col] = label_encoder.fit_transform(df[col].astype(str))\n",
        "\n",
        "# Step 6: Normalize numerical columns\n",
        "scaler = MinMaxScaler()\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
        "\n",
        "# Step 7: Split into features and target\n",
        "X = df.drop('survived', axis=1)\n",
        "y = df['survived']\n",
        "\n",
        "# Step 8: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 9: Train Decision Tree Classifier\n",
        "tree_model = DecisionTreeClassifier(max_depth=4, random_state=42)  # Limit depth for clear visualization\n",
        "tree_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 10: Evaluate model\n",
        "y_pred = tree_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n Decision Tree Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "## Step 11: Visualize the tree\n",
        "#plt.figure(figsize=(20, 10))\n",
        "#plot_tree(tree_model, feature_names=X.columns, class_names=['Not Survived', 'Survived'],\n",
        " #         filled=True, rounded=True, fontsize=12)\n",
        "#plt.title(\"Decision Tree for Titanic Survival\")\n",
        "#plt.show()\n",
        "\n",
        "# Step 12: Predict on a new sample (e.g. hypothetical passenger)\n",
        "# NOTE: Input values must match the order and scaling of your features\n",
        "# Example: [pclass, sex, age, sibsp, parch, fare, embarked, class, who, adult_male, alone]\n",
        "# We'll use the first row from the training set as an example of a \"new passenger\"\n",
        "# Fix: Create a new DataFrame with correct feature names\n",
        "sample = pd.DataFrame([X.iloc[0].values], columns=X.columns)\n",
        "prediction = tree_model.predict(sample)#\n",
        "\n",
        "print(\"\\n Prediction for new sample:\", \"Survived\" if prediction[0] == 1 else \"Not Survived\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1mAZYFWYc6u",
        "outputId": "50f4eabc-2f5f-4765-93ca-b526d3272aae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Decision Tree Accuracy: 0.81\n",
            "\n",
            " Prediction for new sample: Not Survived\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# âœ… Updated preprocessing function\n",
        "def preprocess(df, target_column):\n",
        "    df = df.copy()  # prevent chained assignment\n",
        "    df = df.dropna()\n",
        "\n",
        "    # Label encode object and category columns\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == 'object' or str(df[col].dtype) == 'category':\n",
        "            df[col] = LabelEncoder().fit_transform(df[col].astype(str))\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df.drop(target_column, axis=1)\n",
        "    y = df[target_column]\n",
        "\n",
        "    # Scale numerical features\n",
        "    scaler = MinMaxScaler()\n",
        "    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "    return train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Decision tree pruning strategies\n",
        "pruning_params = [\n",
        "    {'max_depth': 3},\n",
        "    {'max_depth': 5},\n",
        "    {'min_samples_split': 10},\n",
        "    {'min_samples_leaf': 5},\n",
        "    {'max_leaf_nodes': 10}\n",
        "]\n",
        "\n",
        "# Datasets: (name, df, target_column)\n",
        "datasets = []\n",
        "\n",
        "# 1. Titanic\n",
        "titanic = sns.load_dataset('titanic')\n",
        "titanic = titanic.drop(columns=['deck', 'embark_town', 'alive'])\n",
        "datasets.append(('Titanic', titanic, 'survived'))\n",
        "\n",
        "# 2. Iris\n",
        "iris = load_iris(as_frame=True)\n",
        "datasets.append(('Iris', iris.frame, 'target'))\n",
        "\n",
        "# 3. Wine\n",
        "wine = load_wine(as_frame=True)\n",
        "datasets.append(('Wine', wine.frame, 'target'))\n",
        "\n",
        "# 4. Breast Cancer\n",
        "cancer = load_breast_cancer(as_frame=True)\n",
        "datasets.append(('Breast Cancer', cancer.frame, 'target'))\n",
        "\n",
        "# 5. Penguins\n",
        "penguins = sns.load_dataset('penguins')\n",
        "penguins = penguins.drop(columns=['island', 'species'])\n",
        "penguins = penguins[penguins['sex'].notna()]  # drop missing targets\n",
        "penguins['sex'] = penguins['sex'].map({'Male': 1, 'Female': 0})\n",
        "datasets.append(('Penguins', penguins, 'sex'))\n",
        "\n",
        "# Main loop to collect results\n",
        "results = []\n",
        "\n",
        "for dataset_name, df, target in datasets:\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test = preprocess(df, target)\n",
        "\n",
        "        for params in pruning_params:\n",
        "            clf = DecisionTreeClassifier(**params, random_state=42)\n",
        "            clf.fit(X_train, y_train)\n",
        "            y_pred = clf.predict(X_test)\n",
        "            acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "            results.append({\n",
        "                'Dataset': dataset_name,\n",
        "                'Pruning Method': str(params),\n",
        "                'Accuracy': round(acc * 100, 2)\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error with dataset {dataset_name}: {e}\")\n",
        "\n",
        "# Create summary table\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Pivot for comparison\n",
        "comparison_table = results_df.pivot(index='Dataset', columns='Pruning Method', values='Accuracy')\n",
        "print(\"\\n Decision Tree Pruning Comparison:\\n\")\n",
        "print(comparison_table.round(2))"
      ],
      "metadata": {
        "id": "pCDyD_I1iYWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the text dataset (selecting 4 categories for speed)\n",
        "categories = ['sci.space', 'comp.graphics', 'rec.sport.baseball', 'talk.politics.misc']\n",
        "newsgroups = fetch_20newsgroups(subset='all', categories=categories)\n",
        "\n",
        "# Vectorize the text using TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=2000)\n",
        "X = vectorizer.fit_transform(newsgroups.data)\n",
        "y = newsgroups.target\n",
        "\n",
        "# Define evaluation metrics\n",
        "scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'precision': make_scorer(precision_score, average='macro'),\n",
        "    'recall': make_scorer(recall_score, average='macro'),\n",
        "    'f1': make_scorer(f1_score, average='macro')\n",
        "}\n",
        "\n",
        "# -------------------------\n",
        "#  Without Pruning\n",
        "# -------------------------\n",
        "tree_no_prune = DecisionTreeClassifier(random_state=42)\n",
        "scores_no_prune = cross_validate(tree_no_prune, X, y, cv=10, scoring=scoring)\n",
        "\n",
        "# -------------------------\n",
        "#  With Pruning\n",
        "# -------------------------\n",
        "tree_pruned = DecisionTreeClassifier(max_depth=10, min_samples_split=10, random_state=42)\n",
        "scores_pruned = cross_validate(tree_pruned, X, y, cv=10, scoring=scoring)\n",
        "\n",
        "# -------------------------\n",
        "# ðŸ“Š Compare Results\n",
        "# -------------------------\n",
        "def summarize_scores(scores):\n",
        "    return {\n",
        "        'Accuracy': round(scores['test_accuracy'].mean() * 100, 2),\n",
        "        'Precision': round(scores['test_precision'].mean() * 100, 2),\n",
        "        'Recall': round(scores['test_recall'].mean() * 100, 2),\n",
        "        'F1 Score': round(scores['test_f1'].mean() * 100, 2)\n",
        "    }\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'Without Pruning': summarize_scores(scores_no_prune),\n",
        "    'With Pruning': summarize_scores(scores_pruned)\n",
        "})\n",
        "\n",
        "print(\" Decision Tree Text Classification Results (10-fold CV):\\n\")\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A3qY3H2k_Tc",
        "outputId": "45154f58-a4a0-4e63-9867-1c684fda1bf8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Decision Tree Text Classification Results (10-fold CV):\n",
            "\n",
            "           Without Pruning  With Pruning\n",
            "Accuracy             82.70         71.55\n",
            "Precision            82.98         77.07\n",
            "Recall               82.70         71.32\n",
            "F1 Score             82.73         72.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris(as_frame=True)\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = rf.predict(X_test)\n",
        "print(f\"âœ… Accuracy on Iris: {accuracy_score(y_test, y_pred):.2f}\")\n",
        "\n",
        "##Visualize One Tree from the Forest\n",
        "#plt.figure(figsize=(20, 10))\n",
        "#plot_tree(rf.estimators_[0],\n",
        " #         feature_names=iris.feature_names,\n",
        "  #        class_names=iris.target_names,\n",
        "   #       filled=True, rounded=True, max_depth=3)\n",
        "#plt.title(\"ðŸŒ³ Decision Tree from Iris Random Forest\")\n",
        "#plt.show()\n",
        "##Predict New Sample\n",
        "sample = pd.DataFrame([X_test.iloc[0].values], columns=X.columns)\n",
        "prediction = rf.predict(sample)\n",
        "\n",
        "print(\"ðŸ”® Predicted species:\", iris.target_names[prediction[0]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcnzr4F6mZcl",
        "outputId": "5a348527-d61c-4723-e1ba-9121e357b7ac"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Accuracy on Iris: 1.00\n",
            "ðŸ”® Predicted species: versicolor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the student performance dataset\n",
        "data = fetch_openml(name=\"student-performance-uci\", version=1, as_frame=True)\n",
        "df = data.frame\n",
        "\n",
        "#print(\"Columns in dataset:\", df.columns.tolist())\n",
        "\n",
        "# Step: Decide how to form the target\n",
        "# If G3 exists, use it. If G1, G2 also exist, we can drop them or keep them depending on your problem.\n",
        "# We'll make a binary pass/fail: pass if final grade >= 10 (you can adjust threshold)\n",
        "\n",
        "if 'G3' in df.columns:\n",
        "    df['pass'] = (df['G3'].astype(float) >= 10).astype(int)\n",
        "else:\n",
        "    raise ValueError(\"G3 column not found, cannot define pass/fail target\")\n",
        "\n",
        "# Drop all grade columns to prevent leakage (if present)\n",
        "for grade_col in ['G1', 'G2', 'G3']:\n",
        "    if grade_col in df.columns:\n",
        "        df = df.drop(columns=[grade_col])\n",
        "\n",
        "# Encode categorical columns\n",
        "for col in df.select_dtypes(include=['object', 'category']).columns:\n",
        "    df[col] = LabelEncoder().fit_transform(df[col].astype(str))\n",
        "\n",
        "# Features and target\n",
        "X = df.drop('pass', axis=1)\n",
        "y = df['pass']\n",
        "\n",
        "# Split into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict & evaluate\n",
        "y_pred = rf.predict(X_test)\n",
        "print(\" Random Forest Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Visualize one tree\n",
        "#plt.figure(figsize=(20, 10))\n",
        "#plot_tree(rf.estimators_[0],\n",
        " #         feature_names=X.columns,\n",
        "  #        class_names=['Fail', 'Pass'],\n",
        "   #      filled=True, rounded=True, max_depth=3)\n",
        "#plt.title(\"Sample Tree from Random Forest (Student pass/fail prediction)\")\n",
        "#plt.show()\n",
        "\n",
        "# Predict a new sample example\n",
        "# You need to construct a new sample with the same features (encoded) as X\n",
        "# For demonstration, use first test sample:\n",
        "sample = pd.DataFrame([X_test.iloc[0].values], columns=X.columns)\n",
        "pred = rf.predict(sample)\n",
        "print(\" Prediction for sample:\", \"Pass\" if pred[0] == 1 else \"Fail\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWRKfA9Vs0XJ",
        "outputId": "6c7fcac4-8c48-4fb5-a42d-e1cdae987ffd"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Random Forest Accuracy: 0.8769230769230769\n",
            " Prediction for sample: Pass\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "beginner.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}