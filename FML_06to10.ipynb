{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sangitaGIT011/Myproj/blob/main/FML_06to10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Practicle 6\n",
        "#On cleaned dataset, apply Naïve Bayes classification and compare its result with decision tree\n",
        "#and random forest.\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Final ML Classification Comparison\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1. Load and clean dataset\n",
        "# ------------------------------------------------------------\n",
        "# Example: Using the Iris dataset (you can replace with any cleaned dataset)\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "\n",
        "## Create dataframe\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df['species'] = iris.target\n",
        "\n",
        "\n",
        "# Show dataset info\n",
        "\n",
        "#print(\"Dataset Information:\")\n",
        "#print(df.head(), \"\\n\")\n",
        "\n",
        "# Split into features and target\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "# Split into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2. Naïve Bayes Classifier\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "print(\"=== Naïve Bayes Classification ===\")\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "nb_pred = nb.predict(X_test)\n",
        "\n",
        "nb_acc = accuracy_score(y_test, nb_pred)\n",
        "print(\"Accuracy:\", round(nb_acc, 3))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, nb_pred))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3. Decision Tree Classifier\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n---------------\")\n",
        "print(\"\\n=== Decision Tree Classification ===\")\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "dt_pred = dt.predict(X_test)\n",
        "\n",
        "dt_acc = accuracy_score(y_test, dt_pred)\n",
        "print(\"Accuracy:\", round(dt_acc, 3))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, dt_pred))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4. Random Forest Classifier\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n---------------\")\n",
        "print(\"\\n=== Random Forest Classification ===\")\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_test)\n",
        "\n",
        "rf_acc = accuracy_score(y_test, rf_pred)\n",
        "print(\"Accuracy:\", round(rf_acc, 3))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, rf_pred))\n",
        "print(\"\\n---------------\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5. Compare Model Accuracies\n",
        "# ------------------------------------------------------------\n",
        "accuracy_results = pd.DataFrame({\n",
        "    'Model': ['Naïve Bayes', 'Decision Tree', 'Random Forest'],\n",
        "    'Accuracy': [nb_acc, dt_acc, rf_acc]\n",
        "})\n",
        "\n",
        "print(\"\\n=== Model Accuracy Comparison ===\")\n",
        "print(accuracy_results)\n",
        "print(\"\\n---------------\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 7. Conclusion\n",
        "# ------------------------------------------------------------\n",
        "best_model = accuracy_results.loc[accuracy_results['Accuracy'].idxmax()]\n",
        "print(\"\\nBest Performing Model:\")\n",
        "print(best_model)\n"
      ],
      "metadata": {
        "id": "4oAUIKzPBwCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Practicle 7 FML\n",
        "#Develop a code to classify spam mail with Naïve Bayes.\n",
        "------------------------------------------\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1. Load Dataset\n",
        "# ------------------------------------------------------------\n",
        "# Example dataset URL (SMS Spam Collection)\n",
        "url = \"https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv\"\n",
        "df = pd.read_csv(url, sep='\\t', header=None, names=['label', 'message'])\n",
        "\n",
        "# #Inspect dataset\n",
        "#print(\"Dataset info:\\n\", df.info())\n",
        "#print(\"\\nFirst 5 rows:\\n\", df.head())\n",
        "\n",
        "# Encode labels (ham=0, spam=1)\n",
        "df['label_num'] = df.label.map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2. Train-Test Split\n",
        "# ------------------------------------------------------------\n",
        "X = df['message']\n",
        "y = df['label_num']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3. Text Preprocessing (Convert text to numerical features)\n",
        "# ------------------------------------------------------------\n",
        "# Convert messages to a bag-of-words matrix\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(X_train)\n",
        "X_test_counts = count_vect.transform(X_test)\n",
        "\n",
        "# Optional: TF-IDF transformation\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4. Train Naïve Bayes Classifier\n",
        "# ------------------------------------------------------------\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = nb_model.predict(X_test_tfidf)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5. Evaluate Model\n",
        "# ------------------------------------------------------------\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nAccuracy of Naïve Bayes Spam Classifier: {acc:.3f}\\n\")\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Ham','Spam']))\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 6. Test with new sample messages\n",
        "# ------------------------------------------------------------\n",
        "sample_msgs = [\"Congratulations! You won a free iPhone. Click here to claim.\",\n",
        "               \"Hi mom, can we meet tomorrow?\"]\n",
        "sample_counts = count_vect.transform(sample_msgs)\n",
        "sample_tfidf = tfidf_transformer.transform(sample_counts)\n",
        "sample_pred = nb_model.predict(sample_tfidf)\n",
        "\n",
        "for msg, label in zip(sample_msgs, sample_pred):\n",
        "    print(f\"\\nMessage: {msg}\\nPredicted Label: {'Spam' if label==1 else 'Ham'}\")\n"
      ],
      "metadata": {
        "id": "6PJC0SK_HPpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Practicle 8\n",
        "#Estimate the accuracy of Naïve Bayes algorithm using 10-fold cross validation on the housevotes-84 data set.\n",
        "# ------------------------------------------------------------\n",
        "# Naïve Bayes 10-Fold Cross Validation on HouseVotes-84\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1. Load Dataset\n",
        "# ------------------------------------------------------------\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data\"\n",
        "\n",
        "# Column names from UCI dataset\n",
        "columns = ['party', 'handicapped-infants', 'water-project-cost-sharing', 'adoption-of-the-budget-resolution',\n",
        "           'physician-fee-freeze', 'el-salvador-aid', 'religious-groups-in-schools',\n",
        "           'anti-satellite-test-ban', 'aid-to-nicaraguan-contras', 'mx-missile', 'immigration',\n",
        "           'synfuels-corporation-cutback', 'education-spending', 'superfund-right-to-sue',\n",
        "           'crime', 'duty-free-exports', 'export-administration-act-south-africa']\n",
        "\n",
        "df = pd.read_csv(url, header=None, names=columns)\n",
        "\n",
        "# Replace '?' with NaN and drop rows with missing values\n",
        "df.replace('?', pd.NA, inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Encode categorical features (y/n → 1/0)\n",
        "vote_cols = df.columns[1:]\n",
        "for col in vote_cols:\n",
        "    df[col] = df[col].map({'y': 1, 'n': 0})\n",
        "\n",
        "# Encode target variable (party: Democrat=0, Republican=1)\n",
        "le = LabelEncoder()\n",
        "df['party'] = le.fit_transform(df['party'])\n",
        "\n",
        "# Split into X and y\n",
        "X = df[vote_cols]\n",
        "y = df['party']\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2. Naïve Bayes with 10-Fold Cross Validation\n",
        "# ------------------------------------------------------------\n",
        "nb = CategoricalNB()\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "scores = cross_val_score(nb, X, y, cv=kf)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3. Display Results\n",
        "# ------------------------------------------------------------\n",
        "print(\"10-Fold Cross Validation Accuracy Scores:\\n\", scores)\n",
        "print(\"\\nMean Accuracy: {:.3f}\".format(scores.mean()))\n",
        "print(\"Standard Deviation: {:.3f}\".format(scores.std()))\n"
      ],
      "metadata": {
        "id": "b7EwKAT7J1f_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Practicle 9\n",
        "#Develop a feed forward neural network with backpropagation function to improve a\n",
        "#handwritten character recognition system\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1. Load and Preprocess Data\n",
        "# ------------------------------------------------------------\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to [0, 1]\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "print(\"Training set shape:\", X_train.shape, y_train_cat.shape)\n",
        "print(\"Test set shape:\", X_test.shape, y_test_cat.shape)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2. Build Feedforward Neural Network\n",
        "# ------------------------------------------------------------\n",
        "model = Sequential()\n",
        "\n",
        "# Flatten input 28x28 image to 784 vector\n",
        "model.add(Flatten(input_shape=(28,28)))\n",
        "\n",
        "# Hidden layer 1\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Hidden layer 2\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer (10 classes)\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3. Train Model\n",
        "# ------------------------------------------------------------\n",
        "history = model.fit(\n",
        "    X_train, y_train_cat,\n",
        "    validation_split=0.1,\n",
        "    epochs=15,\n",
        "    batch_size=128,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4. Evaluate Model\n",
        "# ------------------------------------------------------------\n",
        "loss, accuracy = model.evaluate(X_test, y_test_cat)\n",
        "print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5. Predict & Confusion Matrix\n",
        "# ------------------------------------------------------------\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 7. Test on New Sample Images\n",
        "# ------------------------------------------------------------\n",
        "plt.figure(figsize=(1,1))\n",
        "for i in range(5):\n",
        "    plt.subplot(1,5,i+1)\n",
        "    plt.imshow(X_test[i], cmap='gray')\n",
        "    #plt.title(f\"Pred: {y_pred[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZEO3noRwKI2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Practicle 10\n",
        "#Develop a neural network, use learning functions and tune the parameters to reduce the mean\n",
        "#square error for recognizing the face.\n",
        "# ------------------------------------------------------------\n",
        "# Neural Network for Face Recognition\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1. Load LFW Dataset\n",
        "# ------------------------------------------------------------\n",
        "lfw = fetch_lfw_people(min_faces_per_person=50, resize=0.5)\n",
        "X = lfw.images\n",
        "y = lfw.target\n",
        "target_names = lfw.target_names\n",
        "n_classes = len(target_names)\n",
        "\n",
        "print(\"Dataset shape:\", X.shape)\n",
        "print(\"Number of classes:\", n_classes)\n",
        "\n",
        "# Normalize pixel values\n",
        "X = X / 255.0\n",
        "\n",
        "# Flatten images for feedforward network\n",
        "X_flat = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# One-hot encode labels\n",
        "y_cat = to_categorical(y, num_classes=n_classes)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_flat, y_cat, test_size=0.2, random_state=42)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2. Build Neural Network\n",
        "# ------------------------------------------------------------\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_shape=(X_flat.shape[1],)))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(n_classes, activation='softmax'))  # Output layer\n",
        "\n",
        "# Compile model with MSE loss\n",
        "optimizer = Adam(learning_rate=0.001)  # You can tune learning rate\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3. Train Model\n",
        "# ------------------------------------------------------------\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "# ------------------------------------------------------------\n",
        "# 4. Evaluate Model\n",
        "# ------------------------------------------------------------\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test Mean Squared Error: {loss:.4f}\")\n",
        "\n",
        "# Predict for MSE calculation manually\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Calculated MSE: {mse:.4f}\")"
      ],
      "metadata": {
        "id": "n4pEQwb9N374"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}